# -*- coding: utf-8 -*-
"""music recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12bd6uybQJpKs1XCax7feLS5yX19RM-Gb
"""

import numpy as np
import pandas as pd

df=pd.read_csv('/content/songdata.csv')
df.shape     #to see dataset rows and column
df=df.sample(n=5000).drop('link',axis=1).reset_index(drop=True) #first we took 5000 rows from dset, then remove link column and then we make it
#in order wise the 5000 rows in dataset

df.head(100)

"""#Cleaning the text"""

df['text'][0]

df['text']=df['text'].str.lower().replace(r'^\w\s',' ').replace(r'\n',' ',regex=True) #first we convert the text in lower case and then we have
#removed the \n from the text to clean it we have keep the word and space other all we have removed

df.head()

"""#Stemming

its a process where we make the repeating word into base word love,loved,loving== love and second we converting a song text in token or words so we can make recommendation
"""

from nltk.tokenize import RegexpTokenizer
from nltk.stem.porter import PorterStemmer

def tokenizing(txt):
    stemmer = PorterStemmer()
    tokenizer = RegexpTokenizer(r'\w+')  # Splits on words only (removes punctuation)
    tokens = tokenizer.tokenize(txt)  #it convert sentence into token or word
    stemming = [stemmer.stem(w) for w in tokens] #we made new list and it make steming of words
    return ' '.join(stemming)

df['text']=df['text'].apply(lambda x: tokenizing(x))   #passes the text in df one by one to tokenizing funcation

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

tfid= TfidfVectorizer(stop_words='english') #we are removing those words that have no meaning is, from etc
matrix = tfid.fit_transform(df['text'])  #and now we are making vectors of that text

matrix.shape

similarity=cosine_similarity(matrix) #it will get the similarity between song or vector

def recommendation(song_df):   #similarity function
    idx = df[df['song'] == song_df].index[0]
    distances = sorted(list(enumerate(similarity[idx])),reverse=True,key=lambda x:x[1])

    songs = []
    for m_id in distances[1:6]:
        songs.append(df.iloc[m_id[0]].song)

    return songs

recommendation('Imagine')

import pickle
pickle.dump(similarity,open('similarity.pkl','wb'))
pickle.dump(df,open('df.pkl','wb'))